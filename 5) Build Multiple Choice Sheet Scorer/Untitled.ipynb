{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Choice Grader with OpenCV.\n",
    "\n",
    "Hi folks, This is another interesting episode of the tutorial using opencv. In this episode, we are going to grade multiple choice questions using OpenCV and python. The idea is indeed simple. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 1) we detect the four image itself and obtain the top-down view of the image like that of a properly scanned one. I have explained this in my previous tutorial, it will be implemented here again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Having detected the four coners of the image, as well as obtaining a scanned view, we locate the positions of all the options and arrange them per question, that is 5 options to 1 question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Next we detect the shaded option by looping through the options to see which has a different background colour due to shading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Lastly, and finally, we score by confirming if the shaded option matches the answer key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Let's code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Import packages.\n",
    "first and as usual, we import the packages we need, if you are new, the packages that might be quite new to you are 1) The OpenCV package: The package was originally developed by Intel and also contributed to by quite some special people, it is a very important tool in exploring images in python, as well as computer Vision. 2) Thanks to adrian Rosbrock, he created the imutils package which includes sets of convienience functions that are complicated using the opencv package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np \n",
    "import imutils\n",
    "import cv2\n",
    "from imutils import contours as contour_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Answer key\n",
    "Here, i just gave the answer key, starting from question 1 which corresponds to 0, in my answer key and the corresponding option.( A is 0, B is 1, C is 2, D is 3 and E is 4 ). so what i have doen here is (question1: option A, qustion 2: option B,......e.t.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the expected answer key where 0 is the first question..... e.t.c\n",
    "ANSWER_KEY = {0:0, 1:1, 2:1, 3:0, 4:3, 5:4, 6:4, 7:0, 8:1, 9:0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load in the image.\n",
    "next, we load in the image, convert it to a grayscale, blurr the grayscaled image, then use canny to detect the edges of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the input image \n",
    "image = cv2.imread(\"victor_script.JPG\")\n",
    "image  = cv2.resize(image,(416*2,312*2))\n",
    "orig_image = image.copy()\n",
    "# next we grayscale the image.\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Next step is to blur the image.\n",
    "blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "# Find edges using the canny edge detection. Make sure you blurr before finding edges.\n",
    "edged = cv2.Canny(blurred, 70,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624, 832, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quick peek.\n",
    "just to see all found edges in the image, as well as the read in image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imshow(\" blurred  image\", blurred)\n",
    "cv2.imshow(\" original image\", image)\n",
    "cv2.imshow(\" edges of image\", edged)\n",
    "cv2.imshow(\" gray-scale of image\", gray)\n",
    "cv2.imshow(\" blurred gray-scale of image\", blurred)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Find Document Edge.\n",
    "Although, i have properly explained and used this step in some of my previous tutorials, the idea here is to find all the contours, sort the contours by area, then approximate the contour shape. The intution is that the largest rectangular contour is most likely the document edge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND CONTOURS\n",
    "contours = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# grab contours with imutils\n",
    "contours = imutils.grab_contours(contours)\n",
    "# our major interest here is the document contour, initialize to none.\n",
    "#doc_contour = None\n",
    "\n",
    "# sort all found contours by area in decending order.\n",
    "if  len(contours) > 0:\n",
    "    contours = sorted(contours, key = cv2.contourArea, reverse = True)\n",
    "# approximate contours and choose contour with exactly 4 sides as the edge.\n",
    "for contour in contours:\n",
    "    perimeter = cv2.arcLength(contour, True) # convert contour points to lines.\n",
    "    approximated = cv2.approxPolyDP(contour, 0.02*perimeter, True) #Approximate these lines to shape\n",
    "    if len(approximated) == 4: # if the approximated shape has 4 sides.\n",
    "        doc_contour = approximated  # The document contour \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Quick Peek.\n",
    "Draw the contour you have proposed to be the document, and view it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw the document edges.\n",
    "cv2.drawContours(image,[doc_contour], -1, (255,0,0), 2)\n",
    "# preview drawn contours.\n",
    "cv2.imshow(\"found document edges\",image)\n",
    "cv2.imwrite(\"output4.jpg\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Functions To Give The Birds Eye View.\n",
    "This two functions help to obtain the birds eye view of an image with the four coners already detected. I have explained this explicitly in my previous tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrange_points(points):\n",
    "    # initialize a list of co-ordinates that will be ordered\n",
    "    # first entry is top-left point, second entry is top-right\n",
    "    # third entry is bottom-right, forth/last point is the bottom left point.\n",
    "    rectangle = np.zeros((4,2), dtype = \"float32\")\n",
    "    \n",
    "    # bottom left point should be the smallest sum\n",
    "    # the top-right point will have the largest sum of point.\n",
    "    sum_points= points.sum(axis =1)\n",
    "    rectangle[0] = points[np.argmin(sum_points)]\n",
    "    rectangle[2] = points[np.argmax(sum_points)]\n",
    "    \n",
    "    \n",
    "    #bottom right will have the smallest difference\n",
    "    #top left will have the largest difference.\n",
    "    diff_points = np.diff(points, axis=1)\n",
    "    rectangle[1] = points[np.argmin(diff_points)]\n",
    "    rectangle[3] = points[np.argmax(diff_points)]\n",
    "    \n",
    "    \n",
    "    # return order of co-ordinates.\n",
    "    return rectangle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# set four points.\n",
    "def set_four_points(image, points):\n",
    "    # obtain order of points and unpack.\n",
    "    rectangle = arrange_points(points)\n",
    "    (top_left,top_right,bottom_right,bottom_left) = rectangle\n",
    "    # let's compute width of the rectangle.\n",
    "    # using formular for distance between two points\n",
    "    left_height = np.sqrt(((top_left[0]-bottom_left[0])**2) + ((top_left[1]-bottom_left[1])**2))\n",
    "    right_height = np.sqrt(((top_right[0]-bottom_right[0])**2) + ((top_right[1]-bottom_right[1])**2))\n",
    "    top_width = np.sqrt(((top_right[0]-top_left[0])**2) + ((top_right[1]-top_left[1])**2))\n",
    "    bottom_width = np.sqrt(((bottom_right[0]-bottom_left[0])**2) + ((bottom_right[1]-bottom_left[1])**2))\n",
    "    \n",
    "    maxheight = max(int(left_height), int(right_height))\n",
    "    maxwidth  = max(int(top_width), int(bottom_width))\n",
    "    \n",
    "    destination = np.array([\n",
    "        [0,0],\n",
    "        [maxwidth -1,0],\n",
    "        [maxwidth -1, maxheight-1],\n",
    "        [0, maxheight - 1]], dtype = \"float32\")\n",
    "    \n",
    "    \n",
    "    matrix = cv2.getPerspectiveTransform(rectangle, destination)\n",
    "    warped = cv2.warpPerspective(image, matrix, (maxwidth,maxheight))\n",
    "    \n",
    "    return warped   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Give The Birds Eye View.\n",
    "since we've set-up the functions, we use it to obtain the top-down view of the image. The paper here is the scan of the original image while the warped is the scan of the gray scaled image which is more important to perform the subsequent operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the scanned image of the answer sheet.\n",
    "paper = set_four_points(orig_image, doc_contour.reshape(4,2))\n",
    "# get the scanned image of the gray scale which is very much ideal for finding contours.\n",
    "warped = set_four_points(gray, doc_contour.reshape(4,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quick Peek.\n",
    "Check out the scanned image, as compared to the initial original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"paper_scanned\", paper)\n",
    "cv2.imshow(\"image\", warped)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Threshold The image.\n",
    "The nextstep is to obtain the image threhold, i used the thresh otsu which is much more lighter than some other thresholds. The iidea behind the threshold binary inverse which i included is the invert the otsu thresholding which would help us obtain a more focused view of the contents of the document as compared with the OTSU Threshold alone. This of course would help us to focus on the options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the black and white scan to the threshold.\n",
    "thresh = cv2.threshold(warped, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quick Peek.\n",
    "Let's preview the threshold application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"paper_scanned\", warped)\n",
    "cv2.imshow(\"image\", thresh)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Find Options Contours Only.\n",
    "Next crucial step is to obtain the options contours in the image. To do this, we find contours using the cv2.findContours(), Next we use imutils to grab the contours, i initialized a list to save my question_contours. The next step is to loop through all the contours and pick only those contours that meet my custom conditions. I'm not a magician, i used trial by error method to obtain those conditions under my IF statement. To even be able to specify conditions, i needed to obtain some reasonable measurements from all the contours. That's where my cv2.boundingRect() comes in which outputs, the position and dimension(width and height) of the input contour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### >> Finally, i save these contours in my question_contours list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find contours in the thresholded image\n",
    "contours = cv2.findContours(thresh.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "# grab the contours\n",
    "contours = imutils.grab_contours(contours)\n",
    "# initialize a list to secure the contours of the options\n",
    "question_contours = []\n",
    "\n",
    "#loop through the contours to specifically select the options part alone.\n",
    "for contour in contours:\n",
    "    # get x,y, positions and width and height of box.\n",
    "    (x,y,w,h)  = cv2.boundingRect(contour)\n",
    "    # print(x,y,w,h) # if you like to see.\n",
    "    ar = w/float(h) # grab your true aspect ratio of box.\n",
    "    \n",
    "    if w>11 and h>11 and ar>1.5:\n",
    "        question_contours.append(contour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quick Peek\n",
    "Let's see the contours as well as how well the conditions worked to trap options ONLY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = paper.copy() # get a copy of the paper script to avoid tampering\n",
    "cv2.drawContours(sample,question_contours,-1,(225,0,0),2)\n",
    "# draw all found contours to check if your proposed constraints are very rigid and strict.\n",
    "# show the image.\n",
    "cv2.imshow(\"all options\", sample)\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"output8.jpg\", sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Arrange Contours.\n",
    "After grabbing all the options, the next step is to arrange the contours from top to bottom, this helps to to easily track the contour from each of the option. To understand this futher, the first option A in question 1 is \"contour 1\", and the last \"option E\" in \"question 10\" is \"contour 50\".\n",
    "If you take a look at the number of contours in the question contours list, you'll find out that it is 50, each representing one option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange contours as top-to-bottom.\n",
    "question_contours = contour_manager.sort_contours(question_contours, method = \"top-to-bottom\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Find Shaded Options and Mark Script.\n",
    "To start the code, i first initialized the correct answers to zero, Next, i pick the first question as well as the range of 5 contours which contains the options. Next step is to arrange the contours selecting them 5 each. To do this i used the imutils's contour function which i imported as contour_manager. In the next line, i initialized shaded to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the contours are all set, I worked on all 50 options. To do this, i created another for loop to work on all the 5 options in each question as ordered by the first for loop. The point is, The first for loop loops through each question, The second for loop in it loops through each option in the question of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In looping through the options, i looked for the most white option. What i mean is, if you take a deep look at the thresholded image we are currently working with, you'll discover that the option with the most white background is the shaded one. To obtain this whitest option, i used a black background to mask the image with only the option of interest excluded. i then use the black mask which has a hole (the option of interest) to cover the image. With this, i am then able to count and determine how white the option is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eventually, i save the position of the option with the whitest background which of course is the shaded option. After getting this, i am able to extract the option position in that particular question and then compare with my answer key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next line of code, where i have the If statement, that's where i do the scoring and marking. If the shaded option corresponds with the answer key, i use a green marker and increase score by one.\n",
    "Eventually, After all said and done, i write a text to count in percentage the total score and finally print it out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Code In."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_sample=paper.copy()\n",
    "correct = 0 # initialize score to zero\n",
    "for (question, index) in enumerate(np.arange(0,len(question_contours),5)): # 5 options so 5 contours for each line\n",
    "    contours = contour_manager.sort_contours(question_contours[index:(index + 5)])[0] #picking the 5 contours.\n",
    "    #print(contours)\n",
    "    \n",
    "    shaded = None # initialize shaded option to zero\n",
    "    cv2.drawContours(fast_sample,contours,-1,(0,225,0),2)\n",
    "    cv2.imshow(\"all options\", fast_sample)\n",
    "    cv2.imwrite(\"output{}.jpg\".format(index+100), fast_sample)\n",
    "    cv2.waitKey(0)\n",
    "    # for each option in the first 5 contours.\n",
    "    for (option_position, contour) in enumerate(contours):\n",
    "        mask = np.zeros(thresh.shape, dtype = \"uint8\") # give us a mask exactly the size of the answer sheet.\n",
    "        cv2.drawContours(mask, [contour], -1, (225,225,225), -1) #draw a white box around the option.\n",
    "        mask = cv2.bitwise_and(thresh, thresh, mask = mask)# mask whole script except option\n",
    "        total = cv2.countNonZero(mask)# how white is the option?.\n",
    "        if shaded is None or total > shaded[0]: #most white = most shaded.\n",
    "            shaded = (total,option_position) #save shaded position\n",
    "    color  = (0,0,225) #marking ink is red unless:\n",
    "    correct_option = ANSWER_KEY[question] # extract correct option from answers key.\n",
    "    if correct_option == shaded[1]: # use green ink if correct answer == shaded option\n",
    "        color = (0,225,0)\n",
    "        correct = correct+1 # increase score by 1\n",
    "    cv2.drawContours(paper, [contours[correct_option]], -1, color, 3) # draw contours for this question.\n",
    "text = \" score is {}%\".format(correct*10) # collate remark after marking\n",
    "script = paper.copy()# dont spoil the original paper with remarks use a copy\n",
    "cv2.putText(script, text, (100,70), cv2.FONT_HERSHEY_SCRIPT_SIMPLEX, 0.9, (0,0,0), 2) # wtite remark\n",
    "cv2.imshow(\"stuff\", script)# show the whole stuff\n",
    "cv2.waitKey(0)\n",
    "cv2.imwrite(\"output_finale.jpg\", script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The End\n",
    "To use this code on different omr sheet types the Parameters to tweak are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The resizing of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The Threshold parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) The Canny parameters to detect edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) The conditions required to find the options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
